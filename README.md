# Knowledge-Distillation-in-SLMs
A simple implementation of knowledge distillation in Small Language Models (SLMs) using the AG News dataset. Includes from-scratch student and teacher architectures for text classification.
